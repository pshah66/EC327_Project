{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbce959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from  matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers \n",
    "import PIL.Image as Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae35ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Animaldir = \"raw-img\" #Image local directories\n",
    "Test_Animal_dir = 'raw2-img'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4fe44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height_m4 = 256 #Our second input of images at a larger size\n",
    "img_width_m4 = 256\n",
    "img_size_m4 = (256,256)\n",
    "\n",
    "train_animals_m4 = tf.keras.utils.image_dataset_from_directory(\n",
    "  Animaldir,\n",
    "  validation_split=0.2,\n",
    "  label_mode='int',\n",
    "  labels = 'inferred',\n",
    "  class_names = None,\n",
    "  color_mode = 'rgb',\n",
    "  subset=\"training\",\n",
    "  shuffle = True,\n",
    "  seed = 123,\n",
    "  image_size=img_size_m4,\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_animals_m4 = tf.keras.utils.image_dataset_from_directory(\n",
    "  Animaldir,\n",
    "  validation_split=0.2,\n",
    "  label_mode='int',\n",
    "  labels = 'inferred',\n",
    "  class_names = None,\n",
    "  color_mode = 'rgb',\n",
    "  shuffle = True,\n",
    "  seed = 123,\n",
    "  subset=\"validation\",\n",
    "  image_size=img_size_m4,\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27bc880",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.array(train_animals.class_names) #Gets the array of class names\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d45853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE #process efficency\n",
    "\n",
    "train_animals = train_animals.prefetch(buffer_size=AUTOTUNE)\n",
    "val_animals = val_animals.prefetch(buffer_size=AUTOTUNE)\n",
    "test_animals = test_animals.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ed9557",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #New image size for data augmentation for our pre-trained set\n",
    "img_height_v2 = 224\n",
    "img_width_v2 = 224\n",
    "img_size_v2 = (224,224)\n",
    "\n",
    "img_shape = img_size_v2 + (3,)\n",
    "\n",
    "data_augmentation_mobile_v2 = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\",\n",
    "                      input_shape=(img_height_v2,\n",
    "                                  img_width_v2,\n",
    "                                   3)),\n",
    "     layers.RandomRotation(0.2),\n",
    "     layers.RandomZoom(0.1),    \n",
    "  ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d64ee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "\n",
    "train_animals_v2 = tf.keras.utils.image_dataset_from_directory( #New import of photos probably redundant\n",
    "  Animaldir,\n",
    "  validation_split=0.2,\n",
    "  label_mode='int',\n",
    "  labels = 'inferred',\n",
    "  class_names = None,\n",
    "  color_mode = 'rgb',\n",
    "  subset=\"training\",\n",
    "  shuffle = True,\n",
    "  seed = 123,\n",
    "  image_size=img_size_v2,\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_animals_v2 = tf.keras.utils.image_dataset_from_directory(\n",
    "  Animaldir,\n",
    "  validation_split=0.2,\n",
    "  label_mode='int',\n",
    "  labels = 'inferred',\n",
    "  class_names = None,\n",
    "  color_mode = 'rgb',\n",
    "  shuffle = True,\n",
    "  seed = 123,\n",
    "  subset=\"validation\",\n",
    "  image_size=img_size_v2,\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c64951",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = tf.keras.applications.MobileNetV2(input_shape=img_shape, #Instantiate pretrained model\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd25c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(train_animals_v2))\n",
    "feature_batch = pretrained_model(image_batch)\n",
    "print(feature_batch.shape) #Just general data dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbbfe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model.trainable = False #Freezes upper layers\n",
    "pretrained_model.summary() #All the layers used in the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
