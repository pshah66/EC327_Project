{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12c95ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from  matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers \n",
    "import PIL.Image as Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e9dbe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "Animaldir = \"raw-img\" #Image local directories\n",
    "Test_Animal_dir = 'raw2-img'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7008083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18686 files belonging to 10 classes.\n",
      "Using 14949 files for training.\n",
      "Found 18686 files belonging to 10 classes.\n",
      "Using 3737 files for validation.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32 #Imports image from local directory at our prefered size\n",
    "img_height = 192\n",
    "img_width = 192\n",
    "img_size = (192,192)\n",
    "\n",
    "train_animals = tf.keras.utils.image_dataset_from_directory(\n",
    "  Animaldir,\n",
    "  validation_split=0.2,\n",
    "  label_mode='int',\n",
    "  labels = 'inferred',\n",
    "  class_names = None,\n",
    "  color_mode = 'rgb',\n",
    "  subset=\"training\",\n",
    "  shuffle = True,\n",
    "  seed = 123,\n",
    "  image_size=img_size,\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_animals = tf.keras.utils.image_dataset_from_directory(\n",
    "  Animaldir,\n",
    "  validation_split=0.2,\n",
    "  label_mode='int',\n",
    "  labels = 'inferred',\n",
    "  class_names = None,\n",
    "  color_mode = 'rgb',\n",
    "  shuffle = True,\n",
    "  seed = 123,\n",
    "  subset=\"validation\",\n",
    "  image_size=img_size,\n",
    "  batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d13d9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.array(train_animals.class_names) #Gets the array of class names\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02b77f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential( #Data Augmentation 1\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\",\n",
    "                      input_shape=(img_height,\n",
    "                                  img_width,\n",
    "                                  3)),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.1),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d26e2ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 192, 192, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 192, 192, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 96, 96, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 96, 96, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 48, 48, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 48, 48, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 24, 24, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 36864)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               4718720   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,743,594\n",
      "Trainable params: 4,743,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3 = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)), #I suggest not running this as will take well over 20 minutes\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'), #If you are running this on collab I don't think it will even run\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'), #This adds a layer of dropout at the end of the NN\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model_3.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03413afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "468/468 [==============================] - 136s 290ms/step - loss: 1.9095 - accuracy: 0.3222 - val_loss: 1.6712 - val_accuracy: 0.4215\n",
      "Epoch 2/10\n",
      "468/468 [==============================] - 137s 292ms/step - loss: 1.3686 - accuracy: 0.5302 - val_loss: 1.4456 - val_accuracy: 0.5052\n",
      "Epoch 3/10\n",
      "468/468 [==============================] - 137s 293ms/step - loss: 1.0589 - accuracy: 0.6410 - val_loss: 1.3930 - val_accuracy: 0.5579\n",
      "Epoch 4/10\n",
      "468/468 [==============================] - 137s 293ms/step - loss: 0.7518 - accuracy: 0.7444 - val_loss: 1.5287 - val_accuracy: 0.5438\n",
      "Epoch 5/10\n",
      "468/468 [==============================] - 137s 293ms/step - loss: 0.4940 - accuracy: 0.8347 - val_loss: 1.7059 - val_accuracy: 0.5563\n",
      "Epoch 6/10\n",
      "468/468 [==============================] - 137s 293ms/step - loss: 0.3326 - accuracy: 0.8879 - val_loss: 2.1151 - val_accuracy: 0.5472\n",
      "Epoch 7/10\n",
      "468/468 [==============================] - 137s 293ms/step - loss: 0.2389 - accuracy: 0.9196 - val_loss: 2.2260 - val_accuracy: 0.5451\n",
      "Epoch 8/10\n",
      "468/468 [==============================] - 142s 304ms/step - loss: 0.1962 - accuracy: 0.9361 - val_loss: 2.4746 - val_accuracy: 0.5456\n",
      "Epoch 9/10\n",
      "468/468 [==============================] - 143s 305ms/step - loss: 0.1532 - accuracy: 0.9527 - val_loss: 2.5836 - val_accuracy: 0.5622\n",
      "Epoch 10/10\n",
      "468/468 [==============================] - 138s 294ms/step - loss: 0.1281 - accuracy: 0.9597 - val_loss: 2.8132 - val_accuracy: 0.5528\n"
     ]
    }
   ],
   "source": [
    "results_3 = model_3.fit(train_animals, #Up to 30 minutes of runtime or more\n",
    "                    epochs=10,\n",
    "                    validation_data=val_animals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828114f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
