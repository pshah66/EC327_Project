{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75ff130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from  matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers \n",
    "import PIL.Image as Image\n",
    "from keras.models import Sequential # Our first model takes just a little bit to run (def more than one minute)\n",
    "from keras.layers import Dense # However, collab did not do very good for our model so I suggest running this on jupyter notebook\n",
    "from keras.layers import MaxPooling2D, BatchNormalization\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7810e014",
   "metadata": {},
   "outputs": [],
   "source": [
    "Animaldir = \"raw-img\" #Image local directories\n",
    "Test_Animal_dir = 'raw2-img'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f447cc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18686 files belonging to 10 classes.\n",
      "Using 14949 files for training.\n",
      "Found 18686 files belonging to 10 classes.\n",
      "Using 3737 files for validation.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "img_height_m4 = 256 #Our second input of images at a larger size\n",
    "img_width_m4 = 256\n",
    "img_size_m4 = (256,256)\n",
    "\n",
    "train_animals_m4 = tf.keras.utils.image_dataset_from_directory(\n",
    "  Animaldir,\n",
    "  validation_split=0.2,\n",
    "  label_mode='int',\n",
    "  labels = 'inferred',\n",
    "  class_names = None,\n",
    "  color_mode = 'rgb',\n",
    "  subset=\"training\",\n",
    "  shuffle = True,\n",
    "  seed = 123,\n",
    "  image_size=img_size_m4,\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_animals_m4 = tf.keras.utils.image_dataset_from_directory(\n",
    "  Animaldir,\n",
    "  validation_split=0.2,\n",
    "  label_mode='int',\n",
    "  labels = 'inferred',\n",
    "  class_names = None,\n",
    "  color_mode = 'rgb',\n",
    "  shuffle = True,\n",
    "  seed = 123,\n",
    "  subset=\"validation\",\n",
    "  image_size=img_size_m4,\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c3a6b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.array(train_animals_m4.class_names) #Gets the array of class names\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29055013",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation_v2 = keras.Sequential( #another data augmentation module\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\",\n",
    "                      input_shape=(img_height_m4,\n",
    "                                  img_width_m4,\n",
    "                                   3)),\n",
    "     layers.RandomRotation(0.2),\n",
    "     layers.RandomZoom(0.1),    \n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb98356f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential (Sequential)     (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 256, 256, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 128, 128, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 128, 128, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 64, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 64, 64, 64)        51264     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 32, 32, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 128)       204928    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 16, 16, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 16, 16, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 8, 8, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16384)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               2097280   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,655,018\n",
      "Trainable params: 2,655,018\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.constraints import max_norm #Adds 2 more layers of filters. Intermediate and end dropout\n",
    "model_4 = Sequential([\n",
    "  data_augmentation_v2,\n",
    "  layers.Rescaling(1./255, input_shape=(img_height_m4, img_width_m4, 3)), #Kernal Constraints and data augmentation added\n",
    "  layers.Conv2D(16, (3,3), padding='same', activation='relu',kernel_constraint=max_norm(3.)),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, (3,3), padding='same', activation='relu',kernel_constraint=max_norm(3.)), #Don't try to run this takes hours\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.5),  \n",
    "  layers.Conv2D(64, (5,5), padding='same', activation='relu',kernel_constraint=max_norm(3.)),\n",
    "  layers.MaxPooling2D(), \n",
    "  layers.Conv2D(128, (5,5), padding='same', activation='relu',kernel_constraint=max_norm(3.)),  \n",
    "  layers.MaxPooling2D(), \n",
    "  layers.Conv2D(256, (3,3), padding='same', activation='relu',kernel_constraint=max_norm(3.)),  \n",
    "  layers.MaxPooling2D(),   \n",
    "  layers.Dropout(0.2),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),  \n",
    "  layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model_4.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early = tf.keras.callbacks.EarlyStopping(patience=10,\n",
    "                                          min_delta=0.001,\n",
    "                                          restore_best_weights=True)\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e06e20ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "468/468 [==============================] - 388s 827ms/step - loss: 2.1585 - accuracy: 0.1973 - val_loss: 1.9597 - val_accuracy: 0.2914\n",
      "Epoch 2/30\n",
      "468/468 [==============================] - 386s 824ms/step - loss: 1.8717 - accuracy: 0.3311 - val_loss: 1.7736 - val_accuracy: 0.3773\n",
      "Epoch 3/30\n",
      "468/468 [==============================] - 384s 820ms/step - loss: 1.6440 - accuracy: 0.4180 - val_loss: 1.5981 - val_accuracy: 0.4493\n",
      "Epoch 4/30\n",
      "468/468 [==============================] - 389s 831ms/step - loss: 1.4915 - accuracy: 0.4763 - val_loss: 1.6402 - val_accuracy: 0.4485\n",
      "Epoch 5/30\n",
      "468/468 [==============================] - 406s 866ms/step - loss: 1.4033 - accuracy: 0.5114 - val_loss: 1.3722 - val_accuracy: 0.5264\n",
      "Epoch 6/30\n",
      "468/468 [==============================] - 420s 897ms/step - loss: 1.3361 - accuracy: 0.5338 - val_loss: 1.3907 - val_accuracy: 0.5221\n",
      "Epoch 7/30\n",
      "468/468 [==============================] - 420s 896ms/step - loss: 1.2765 - accuracy: 0.5580 - val_loss: 1.2789 - val_accuracy: 0.5579\n",
      "Epoch 8/30\n",
      "468/468 [==============================] - 418s 893ms/step - loss: 1.2282 - accuracy: 0.5712 - val_loss: 1.3033 - val_accuracy: 0.5499\n",
      "Epoch 9/30\n",
      "468/468 [==============================] - 420s 896ms/step - loss: 1.1707 - accuracy: 0.5950 - val_loss: 1.1968 - val_accuracy: 0.5884\n",
      "Epoch 10/30\n",
      "468/468 [==============================] - 418s 894ms/step - loss: 1.1426 - accuracy: 0.6046 - val_loss: 1.1866 - val_accuracy: 0.5943\n",
      "Epoch 11/30\n",
      "468/468 [==============================] - 420s 896ms/step - loss: 1.0991 - accuracy: 0.6156 - val_loss: 1.1561 - val_accuracy: 0.6045\n",
      "Epoch 12/30\n",
      "468/468 [==============================] - 420s 898ms/step - loss: 1.0690 - accuracy: 0.6307 - val_loss: 1.1811 - val_accuracy: 0.5943\n",
      "Epoch 13/30\n",
      "468/468 [==============================] - 421s 899ms/step - loss: 1.0536 - accuracy: 0.6317 - val_loss: 1.3796 - val_accuracy: 0.5397\n",
      "Epoch 14/30\n",
      "468/468 [==============================] - 421s 900ms/step - loss: 1.0186 - accuracy: 0.6487 - val_loss: 1.1371 - val_accuracy: 0.6029\n",
      "Epoch 15/30\n",
      "468/468 [==============================] - 420s 897ms/step - loss: 0.9862 - accuracy: 0.6596 - val_loss: 1.2617 - val_accuracy: 0.5887\n",
      "Epoch 16/30\n",
      "468/468 [==============================] - 422s 901ms/step - loss: 0.9774 - accuracy: 0.6637 - val_loss: 1.1950 - val_accuracy: 0.5981\n",
      "Epoch 17/30\n",
      "468/468 [==============================] - 421s 900ms/step - loss: 0.9664 - accuracy: 0.6655 - val_loss: 1.1523 - val_accuracy: 0.6203\n",
      "Epoch 18/30\n",
      "468/468 [==============================] - 421s 900ms/step - loss: 0.9514 - accuracy: 0.6707 - val_loss: 1.0531 - val_accuracy: 0.6398\n",
      "Epoch 19/30\n",
      "468/468 [==============================] - 422s 902ms/step - loss: 0.9225 - accuracy: 0.6797 - val_loss: 1.2431 - val_accuracy: 0.5914\n",
      "Epoch 20/30\n",
      "468/468 [==============================] - 422s 901ms/step - loss: 0.9122 - accuracy: 0.6859 - val_loss: 1.1851 - val_accuracy: 0.6074\n",
      "Epoch 21/30\n",
      "468/468 [==============================] - 422s 901ms/step - loss: 0.8839 - accuracy: 0.6965 - val_loss: 1.0677 - val_accuracy: 0.6422\n",
      "Epoch 22/30\n",
      "468/468 [==============================] - 422s 902ms/step - loss: 0.8853 - accuracy: 0.6966 - val_loss: 1.1956 - val_accuracy: 0.6066\n",
      "Epoch 23/30\n",
      "468/468 [==============================] - 422s 902ms/step - loss: 0.8663 - accuracy: 0.6988 - val_loss: 1.2210 - val_accuracy: 0.6040\n",
      "Epoch 24/30\n",
      "468/468 [==============================] - 421s 899ms/step - loss: 0.8547 - accuracy: 0.7008 - val_loss: 1.0357 - val_accuracy: 0.6521\n",
      "Epoch 25/30\n",
      "468/468 [==============================] - 422s 902ms/step - loss: 0.8407 - accuracy: 0.7088 - val_loss: 1.2499 - val_accuracy: 0.5906\n",
      "Epoch 26/30\n",
      "468/468 [==============================] - 422s 902ms/step - loss: 0.8346 - accuracy: 0.7085 - val_loss: 1.1053 - val_accuracy: 0.6353\n",
      "Epoch 27/30\n",
      "468/468 [==============================] - 424s 906ms/step - loss: 0.8153 - accuracy: 0.7167 - val_loss: 1.1634 - val_accuracy: 0.6235\n",
      "Epoch 28/30\n",
      "468/468 [==============================] - 422s 901ms/step - loss: 0.8104 - accuracy: 0.7222 - val_loss: 0.9663 - val_accuracy: 0.6751\n",
      "Epoch 29/30\n",
      "468/468 [==============================] - 422s 902ms/step - loss: 0.7985 - accuracy: 0.7237 - val_loss: 1.1276 - val_accuracy: 0.6318\n",
      "Epoch 30/30\n",
      "468/468 [==============================] - 421s 900ms/step - loss: 0.8017 - accuracy: 0.7241 - val_loss: 1.2050 - val_accuracy: 0.6264\n"
     ]
    }
   ],
   "source": [
    "results_4 = model_4.fit(train_animals_m4, #Takes hours to run\n",
    "                    epochs=30,\n",
    "                    validation_data=val_animals_m4,\n",
    "                       callbacks=[early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb441d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
