{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05c608e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from  matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers \n",
    "import PIL.Image as Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "613ba99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Animaldir = \"raw-img\" #Image local directories\n",
    "Test_Animal_dir = 'raw2-img'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3425ac1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18686 files belonging to 10 classes.\n",
      "Using 14949 files for training.\n",
      "Found 18686 files belonging to 10 classes.\n",
      "Using 3737 files for validation.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32 #Imports image from local directory at our prefered size\n",
    "img_height = 192\n",
    "img_width = 192\n",
    "img_size = (192,192)\n",
    "\n",
    "train_animals = tf.keras.utils.image_dataset_from_directory(\n",
    "  Animaldir,\n",
    "  validation_split=0.2,\n",
    "  label_mode='int',\n",
    "  labels = 'inferred',\n",
    "  class_names = None,\n",
    "  color_mode = 'rgb',\n",
    "  subset=\"training\",\n",
    "  shuffle = True,\n",
    "  seed = 123,\n",
    "  image_size=img_size,\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_animals = tf.keras.utils.image_dataset_from_directory(\n",
    "  Animaldir,\n",
    "  validation_split=0.2,\n",
    "  label_mode='int',\n",
    "  labels = 'inferred',\n",
    "  class_names = None,\n",
    "  color_mode = 'rgb',\n",
    "  shuffle = True,\n",
    "  seed = 123,\n",
    "  subset=\"validation\",\n",
    "  image_size=img_size,\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aa1c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.array(train_animals.class_names) #Gets the array of class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60490da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential( #Data Augmentation 1\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\",\n",
    "                      input_shape=(img_height,\n",
    "                                  img_width,\n",
    "                                  3)),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.1),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35e192a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 192, 192, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 192, 192, 4)       112       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 96, 96, 4)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 36864)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                368650    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 368,762\n",
      "Trainable params: 368,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "from keras.layers import MaxPooling2D, BatchNormalization\n",
    "\n",
    "num_classes = len(class_names)\n",
    "base_model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(4, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),  \n",
    "  layers.Dense(10)\n",
    "])\n",
    "\n",
    "base_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22d89d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "468/468 [==============================] - 48s 101ms/step - loss: 2.2283 - accuracy: 0.3040 - val_loss: 1.8281 - val_accuracy: 0.3613\n",
      "Epoch 2/10\n",
      "468/468 [==============================] - 33s 69ms/step - loss: 1.5600 - accuracy: 0.4749 - val_loss: 1.7952 - val_accuracy: 0.3824\n",
      "Epoch 3/10\n",
      "468/468 [==============================] - 34s 72ms/step - loss: 1.2348 - accuracy: 0.5976 - val_loss: 1.8421 - val_accuracy: 0.3880\n",
      "Epoch 4/10\n",
      "468/468 [==============================] - 34s 73ms/step - loss: 0.9319 - accuracy: 0.7115 - val_loss: 2.0845 - val_accuracy: 0.3687\n",
      "Epoch 5/10\n",
      "468/468 [==============================] - 34s 72ms/step - loss: 0.6665 - accuracy: 0.8113 - val_loss: 2.1246 - val_accuracy: 0.3773\n",
      "Epoch 6/10\n",
      "468/468 [==============================] - 35s 74ms/step - loss: 0.4606 - accuracy: 0.8833 - val_loss: 2.2982 - val_accuracy: 0.3690\n",
      "Epoch 7/10\n",
      "468/468 [==============================] - 35s 75ms/step - loss: 0.3129 - accuracy: 0.9302 - val_loss: 2.5742 - val_accuracy: 0.3663\n",
      "Epoch 8/10\n",
      "468/468 [==============================] - 40s 85ms/step - loss: 0.2050 - accuracy: 0.9619 - val_loss: 2.6596 - val_accuracy: 0.3596\n",
      "Epoch 9/10\n",
      "468/468 [==============================] - 38s 81ms/step - loss: 0.1301 - accuracy: 0.9815 - val_loss: 2.9179 - val_accuracy: 0.3634\n",
      "Epoch 10/10\n",
      "468/468 [==============================] - 39s 84ms/step - loss: 0.0982 - accuracy: 0.9862 - val_loss: 3.0764 - val_accuracy: 0.3690\n"
     ]
    }
   ],
   "source": [
    "result_base = base_model.fit(train_animals, \n",
    "                    epochs=10,\n",
    "                    validation_data=val_animals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8059f469",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
